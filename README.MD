# PTZ Synthetic Camera POC

This is a minimal proof-of-concept project for creating a **synthetic pan-tilt-zoom (PTZ) camera rig** that can be controlled manually over a video. The goal is to collect training data compatible with **LeRobot/SmolVLA** (using a dataset structure similar to `lerobot/pusht`).

---

## Overview

* Load a source video.
* Display it in a window.
* Use **WASD** to tilt/pan and the **mouse wheel** to zoom.
* The viewport acts as a *virtual camera*.
* All user inputs and viewport states are logged frame-by-frame.
* Data is saved directly in a LeRobot-compatible format:

  * MP4 video for `observation.image`
  * Parquet for frame metadata (`observation.state`, `action`, etc.)
  * `meta/info.json` for dataset description

---

## Controls

| Key         | Action                            |
| ----------- | --------------------------------- |
| W / S       | Tilt up / down                    |
| A / D       | Pan left / right                  |
| Mouse Wheel | Zoom in / out                     |
| Space       | Start / stop recording an episode |
| Esc         | Quit application                  |

---

## Movement model and units

The rig combines angular orientation (pan/tilt) with planar translation when
placing the viewport on the source frame:

* **Pan / Tilt** are measured in degrees around the frame centre. Positive pan
  moves the viewport right; positive tilt moves it up.
* **Planar position** (`x`, `y`) uses a centre-origin basis that can be
  expressed in **pixels** (default), **degrees** (converted using the rig FOV),
  or **normalized** units. The values shown in the HUD and stored in the
  dataset use this basis directly.
* **FPS-style movement** (enabled with `--fps-controls`) uses the mouse to pan
  and tilt the viewport directly while respecting the same limits as WASD
  input. In this mode, `W`/`S` perform a dolly zoom (adjusting `zoom_norm`).

Translation is clamped each render so the cropped viewport always stays inside
the frame, respecting the current zoom level and pan/tilt orientation. Zooming
only scales the viewport size (via the exponential `zoom_norm` curve) and does
not rescale the translation units, but because the viewport is smaller more
translation becomes available before hitting the frame bounds.

---

## Requirements

```
pygame-ce
av
numpy
opencv-python
pyarrow
imageio
imageio-ffmpeg
```

Install dependencies:

```
pip install -r requirements.txt
```

---

## Running

```
python main.py --video path/to/input.mp4 --out_dir dataset_out --size 256 --fps 24
```

Then control the viewport using the keys above. When done, press **Space** to finish the episode and **Esc** to exit.

Use the optional `--pan-speed`, `--tilt-speed`, and `--zoom-step` flags to tune how fast the virtual camera moves while recording (defaults match the current behaviour). For example, a slower pan/tilt with finer zoom control can be launched with:

```
python main.py --video ... --out_dir ... --pan-speed 1.0 --tilt-speed 1.0 --zoom-step 0.02
```

---

## Output Structure

```
dataset_out/
├── meta/info.json
├── data/
│   └── chunk-000/
│       └── episode_000000.parquet
└── videos/
    └── chunk-000/
        └── observation.image/
            └── episode_000000.mp4
```

---

## Next Steps

* Add autofocus (focus/dfocus channel)
* Add multi-task instructions or multiple clips
* Integrate automatic metadata counting

---

**Author:** Generated by Codex for quick POC development
